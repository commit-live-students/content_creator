{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1 : Why Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-1: Given ($\\theta_0$,$\\theta_1$)= (3,2), $y_{true}$=200, what would be $y - y_{true}$ for x=100?\n",
    "\n",
    "A) 3 [Correct]\n",
    "\n",
    "B) -3\n",
    "\n",
    "C) 102\n",
    "\n",
    "D) -102\n",
    "\n",
    "**Explanation:** \n",
    "\n",
    "Equation of the given line will be\n",
    "\n",
    "y=$\\theta_0$ + $\\theta_1$x\n",
    "\n",
    "y=3 + 2x\n",
    "\n",
    "For x= 100,\n",
    "\n",
    "y= 3+200= 203\n",
    "\n",
    "Therefore $y - y_{true}$=203-200=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-2: A regression analysis is inappropriate when the pattern of data points form a spiral.\n",
    "\n",
    "A) True [Correct]\n",
    "\n",
    "B) False\n",
    "\n",
    "**Explanation:**\n",
    "Assumption of Linear Regression is that the relationship between response (Dependent Variables) and feature variables (Independent Variables) should be linear.\n",
    "Linear regression only captures the linear relationship, as its trying to fit a linear model to the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-3: Which of the following is not an assumption of Linear Regression modeling?\n",
    "\n",
    "A) Little or no Multicollinearity\n",
    "\n",
    "B) Heteroscadisticity [Correct]\n",
    "\n",
    "C) Homoscadisticity\n",
    "\n",
    "D) Normal distribution of Error Terms\n",
    "\n",
    "**Explanation:**\n",
    "Assumption of Linear Regression is Homoscadisticity not Heteroscadisticity because non-constant variance arises in presence of outliers or extreme leverage values which will result in poor modeling of data by Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-1: The coefficients of the least squares regression line are determined by minimizing the sum of the squares of the\n",
    "\n",
    "A) X-coordinates\n",
    "    \n",
    "B) Y-coordinates\n",
    "    \n",
    "C) residuals [Correct]\n",
    "    \n",
    "\n",
    "**Explanation:** \n",
    "Our goal is to estimate the parameters in the $\\beta$ vector given the equation $\\varepsilon = \\mathbf{y} - X\\beta$. \n",
    "\n",
    "If we take the actual value of the residuals, they might be negative. To avoid that, we take the squared sum of the residuals which is given by $\\varepsilon^T\\varepsilon$ resulting in us having to minimise $\\varepsilon^T\\varepsilon$ \n",
    "\n",
    "If you didn't get this right, head back to the OLS section\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-2: What is the formual for Residuals?\n",
    "\n",
    "A) True value + Predicted Value\n",
    "\n",
    "B) True value - Predicted Value [Correct]\n",
    "\n",
    "C) True value * Predicted Value\n",
    "\n",
    "D) True value /Predicted Value\n",
    "\n",
    "**Explanation**\n",
    "\n",
    "Residuals in a statistical or machine learning model are the differences between observed and predicted values of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Implementing Linear Regression with Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-1: Look at the following:\n",
    "\n",
    "```python\n",
    "\n",
    "# instantiate linear model\n",
    "model = LinearRegression()\n",
    "\n",
    "# fit model on training data\n",
    "model.fit(X_train, (y_train))\n",
    "\n",
    "\n",
    "var = model.predict(X_test)\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "What is `'var'` in the above code snippet?\n",
    "\n",
    "A) Array of residual errors\n",
    "\n",
    "B) Array of predicted values [Correct]\n",
    "\n",
    "C) Array of 0s\n",
    "\n",
    "D) Array of 1s \n",
    "\n",
    "**Explanation**\n",
    "\n",
    "`predict()` function of `LinearRegression()` model(Or any machine learning model) will give out the predicted values for the `test data` based on the fitting of `train data`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "Q-2: RMSE severely punishes large differences in prediction.\n",
    "\n",
    "A) True [Correct]\n",
    "\n",
    "B) False\n",
    "\n",
    "**Explanation**\n",
    "Formula for RMSE is as follows:\n",
    "\n",
    "$$RMSE = {\\sqrt {\\frac{1} {N}{\\sum\\limits_{i = 1}^N {(y_{i} - \\hat{y}_{i} } })^{2} } }$$\n",
    "\n",
    "Since each difference is `squared`, errors end up increasing in factor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept Quiz: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-1: Which of the following is NOT a possible value of the correlation coefficient?\n",
    "\n",
    "A) - 0.9\n",
    "\n",
    "B) 0\n",
    "\n",
    "C) +0.15\n",
    "\n",
    "D) +1.02 [Correct]\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "The correlation coefficient only ranges from [-1,1].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-2: Which of these problems would be more suitable to apply linear regression?\n",
    "\n",
    "A) Find the status of loan repayment\n",
    "\n",
    "B) Find the price of car [Correct]\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "`Finding price of car` is a regression problem whereas `Finding status of loan repayment` is classification problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-3: What is the slope of a line parallel to the X-axis?\n",
    "\n",
    "A) 1\n",
    "    \n",
    "B) 0 [Correct]\n",
    "  \n",
    "**Explanation:** \n",
    "A line parallel to X-Axis will have y=$\\theta_0$[constant]\n",
    "\n",
    "Since $\\theta_1$[Slope]= (y- $\\theta_1$)/x,  (From y= $\\theta_0$ + $\\theta_1$x)\n",
    "\n",
    "we get $\\theta_1$=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-4: The regression line is drawn such that:\n",
    "\n",
    "A) The line goes through more points than any other possible line, straight or curved\n",
    "\n",
    "B) The same number of points are below and above the regression line.\n",
    "\n",
    "C) The sum of the absolute errors is as small as possible. [Correct Answer]\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "Option A will result in overfitting of the model. In other words, if a new unseen data point comes, the model will result in an error.\n",
    "\n",
    "Option B  is equivalent to a line that is no better than predicting a point randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-5: Which of the following metrics can be used for evaluating regression models?\n",
    "\n",
    "A) Accuracy\n",
    "\n",
    "B) R Squared [Correct]\n",
    "\n",
    "C) Adjusted R Squared [Correct]\n",
    "\n",
    "D) MSE / MAE [Correct]\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "Accuracy for regression models is not an ideal metric.The predictions rarely can equal the expected values(Except for overfitting). And if predictions differ from expected values by 1%, the accuracy will be zero,even though these predictions are great"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-6: What will happen to the value of R-squared if we increase the number of features?\n",
    "\n",
    "A) Increase [Correct]\n",
    "\n",
    "B) Remain the same [Correct]\n",
    "\n",
    "C) Decrease\n",
    "\n",
    "**Explanation:**\n",
    "R squared is the proportion of the outcome variance that can be explained by the explanatory variables. \n",
    "R-squared can never decrease on addition of features\n",
    "\n",
    "\n",
    "Let’s consider the following regression model:\n",
    "\n",
    "yi=β0+β1x1i+⋯+βkxki+εi,\n",
    "\n",
    "or in its matrix form:\n",
    "\n",
    "Y=Xβ+ε,\n",
    "\n",
    "where i=1,…,n.\n",
    "\n",
    "R squared is defined as \n",
    "\n",
    "R2=ESSTSS=∑ni=1(y^i−y^¯)2∑ni=1(yi−y¯)2\n",
    "\n",
    "where y^i=yi−ε^. (ESS and TSS stand respectively for Explained Sum of Squares and Total Sum of Squares.)\n",
    "\n",
    "Now, to understand why the R2 inflates when you increase the value of k, you have to recall that a regression minimizes the sum of squared errors, by solving\n",
    "\n",
    "minβ∑ni=1ε2i=minβ∑ni=1(yi−Xiβ)2.\n",
    "\n",
    "The above equation solves for the values of the coefficients such that the squared errors are minimized, or equivalently, for the values of the coefficients such that what you are able to explain, i.e. the R2, is maximized.\n",
    "\n",
    "Therefore, whenever you add a variable to your model, the value of its estimated coefficient can either be zero, in which case the proportion of explained variance (R2) stays unchanged, or take a nonzero value because it improves the quality of the fit. By construction, your R2 cannot be smaller after adding a variable.\n",
    "8.2k Views · View Upvoters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-7: In a simple linear regression model the slope coefficient measures\n",
    "\n",
    "A) the elasticity of Y with respect to X\n",
    "\n",
    "B) the change in Y which the model predicts for a unit change in X [Correct Answer]\n",
    "\n",
    "C) the change in X which the model predicts for a unit change in Y \n",
    "\n",
    "D) the ratio Y/X\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "Slope of a given line is also known as rate of change of y with respect to x and calculated as $\\frac{y_2-y_1}{x_2-x_1}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-8: A “Linear regression” model perfectly fits the training data (train error is zero). Which of the following statement is true?\n",
    "\n",
    "A) Test error is never going to be 0\n",
    "\n",
    "B) Test error is always going to be 0\n",
    "\n",
    "C) Neither of the above [Correct Answer]\n",
    "\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "Test error may be zero, if the test data is perfect representative of train data, otherwise non zero.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-9: For the following image which one of the statements is true?\n",
    "\n",
    "![](sor.png)\n",
    "\n",
    "\n",
    "A) X has higher sum of residuals than Y\n",
    "\n",
    "B) X has lower sum of residuals than Y\n",
    "\n",
    "C) Both have the same sum of residuals [Correct]\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "Both have the same sum of residuals because sum of residuals is always zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-10: Changing the units of measurement of the Y variable will affect all but which one of the following?\n",
    "\n",
    "A) The estimated intercept parameter\n",
    "\n",
    "B) The Total Sum of Squares for the regression\n",
    "\n",
    "C) R squared for the regression [Correct Answer]\n",
    "\n",
    "D) The estimated slope parameter\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "R squared value doesn't change with scale of Y as it's a ratio with both the numerator and denominator having Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
